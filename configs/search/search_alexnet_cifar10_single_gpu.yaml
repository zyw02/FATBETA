# Experiment name - Single GPU version for 11GB 2080Ti with CIFAR10
name: alexnet_cifar10_single_gpu_search

# Name of output directory. Checkpoints and logs will be saved at `pwd`/output_dir
output_dir: search
training_device: gpu

target_bits: [6, 5, 4, 3, 2]

# Dataset loader
dataloader: 
  dataset: cifar10
  num_classes: 10
  path: ./data/cifar10
  # Batch size for CIFAR10 search on 11GB GPU
  batch_size: 128
  workers: 4
  deterministic: true

resume:
  path: ./training/alexnet_cifar10_single_gpu/alexnet_cifar10_single_gpu_checkpoint.pth.tar
  lean: false

log:
  num_best_scores: 3
  print_freq: 20

#============================ Model ============================================

arch: alexnet
pre_trained: false  # Use trained checkpoint from training phase

#============================ Quantization =====================================

# (default for all layers)
quan:
  act: 
    mode: lsq
    bit: 2
    per_channel: false
    symmetric: false
    all_positive: true

  weight: 
    mode: lsq
    bit: 2
    per_channel: false
    symmetric: false
    all_positive: false
  
  excepts:
    excepts_bits_width: 8
    # Specify quantized bit width for some layers (first and last layers)
    # For AlexNet: features.0 (first conv), classifier.1 (first FC), and classifier.6 (last linear)
    # NOTE: This is the OLD config where classifier.1 is in excepts (8-bit fixed) to match old checkpoint
    # If you want to search a NEW model with classifier.1 using dynamic bits, use search_alexnet_cifar10_single_gpu_v2.yaml
    features.0:  # First conv layer
      act:
        bit: 
        all_positive: false
      weight:
        bit:
    classifier.1:  # First FC layer (8-bit fixed in old checkpoint)
      act:
        bit: 
        all_positive: false
      weight:
        bit:
    classifier.6:  # Last linear layer (index 6 in classifier Sequential)
      act:
        bit:
        all_positive: false
      weight:
        bit:

#============================ Training / Evaluation ============================

search: true
eval: false

# BitOPs limits for CIFAR10 (32x32 input, much smaller than ImageNet 224x224)
# Adjusted for CIFAR10: roughly (32/224)^2 â‰ˆ 0.02x of ImageNet BitOPs
# AlexNet has more parameters than ResNet18, so BitOPs will be higher
bops_limits: 4.4
min_bops_limits: 0.8
start_bit_width: 5

